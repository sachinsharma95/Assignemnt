{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60233c2e-2c2b-44d6-bfb6-66997e10b2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "156c7cf6-9024-4551-a692-3eec2ef89877",
   "metadata": {},
   "source": [
    "# Answer 1\n",
    "Ordinal Encoding and Label Encoding are both techniques used to convert categorical variables into numerical format, but there are differences between them.\n",
    "## Ordinal Encoding :\n",
    "   Assigns a unique integer value to each category, based on the order or rank of the category.<br>\n",
    "   Useful when there is a natural ordering or ranking of the categories, such as in grades (A, B, C, D, F), or sizes (small, medium, large).\n",
    "   \n",
    "   \n",
    "####  Example: \n",
    "For the grade variable, we could use ordinal encoding and assign values of 0 for F, 1 for D, 2 for C, 3 for B, and 4 for A.\n",
    "\n",
    "\n",
    "## Label Encoding:\n",
    "Assigns a unique integer value to each category, without any regard for the order or rank of the categories.\n",
    "<br>\n",
    "Useful when there is no natural ordering or ranking of the categories, or when the number of categories is large.\n",
    "\n",
    "\n",
    "\n",
    "#### Example: \n",
    "\n",
    "For a variable like color, we could use label encoding and assign values of 0 for red, 1 for blue, 2 for green, etc.\n",
    "\n",
    "### When to choose one over the other:\n",
    "\n",
    "- If there is a natural ordering or ranking of the categories, it makes sense to use ordinal encoding to preserve this information in the numerical representation.\n",
    "- If there is no natural ordering or ranking of the categories, or if the number of categories is large, it may be better to use label encoding to simplify the representation and reduce the dimensionality of the data.\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078b2ff9-e583-4ab4-a54a-c2dfffd03caa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Answer 2\n",
    "\n",
    "## Target Guided Ordinal Encoding \n",
    "Target Guided Ordinal Encoding is a technique for encoding categorical variables in a way that takes into account the relationship between the categories and the target variable. \n",
    "It involves assigning a unique ordinal value to each category based on the mean or median of the target variable for that category.\n",
    "\n",
    "### Here's how Target Guided Ordinal Encoding works:\n",
    "\n",
    " 1 For each category in the categorical variable, calculate the mean or median value of the target variable (the variable you are trying to predict) for that category.\n",
    " \n",
    "2 Sort the categories based on these values, so that the category with the lowest mean or median value is assigned the lowest ordinal value, and the category with the highest mean or median value is assigned the highest ordinal value.\n",
    "\n",
    " 3 Replace the original categorical variable with the new ordinal variable.\n",
    " \n",
    "### Here's an example of when you might use Target Guided Ordinal Encoding in a machine learning project:\n",
    "\n",
    "let's say you are working on a project to predict whether a customer will buy a particular product. One of the input variables is the customer's occupation, which is a categorical variable with many categories. Instead of using one-hot encoding or label encoding, which can create a lot of new features or arbitrarily assign values to the categories, you could use Target Guided Ordinal Encoding to encode the occupation variable. By calculating the mean or median purchase rate for each occupation category, you can create a new ordinal variable that takes into account the relationship between occupation and the target variable (purchase rate). This new variable can then be used as input to the machine learning model, potentially improving its performance.\n",
    "\n",
    "\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf187b9b-8906-4e55-b1d8-25146ab2c9d2",
   "metadata": {},
   "source": [
    "# Answer 3\n",
    "## Covariance\n",
    "- Covariance is a measure of the degree to which two variables vary together.\n",
    "\n",
    "- It measures the direction and strength of the linear relationship between two variables. \n",
    "\n",
    "- If the covariance between two variables is positive, it means that they tend to increase or decrease together. If the covariance is negative, it means that as one variable increases, the other tends to decrease. If the covariance is zero, it means that there is no linear relationship between the variables.\n",
    "\n",
    "### Importances of Covariances\n",
    "Covariance is important in statistical analysis because it is used to understand the relationship between variables, and to quantify the degree to which changes in one variable are associated with changes in another variable. This is particularly useful in fields such as finance, where understanding the relationship between different stocks or investments is crucial for making informed decisions.\n",
    "\n",
    "# calculation\n",
    "##  Covariance is calculated using the formula:\n",
    "\n",
    "### cov(X,Y) = Σ [ (xi - μx) * (yi - μy) ] / (n - 1)\n",
    "\n",
    "### Where:\n",
    "\n",
    "#### X and Y are two variables\n",
    "#### xi and yi are the individual values of X and Y, respectively\n",
    "### μx and μy are the means of X and Y, respectively\n",
    "### n is the number of observations\n",
    "\n",
    "\n",
    "The numerator of this formula calculates the sum of the products of the deviations of each observation from their respective means, while the denominator adjusts for the number of observations.\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3ef87c-b8e5-415e-bae4-48fe219f840e",
   "metadata": {},
   "source": [
    "Q4. For a dataset with the following categorical variables: Color (red, green, blue), Size (small, medium,\n",
    "large), and Material (wood, metal, plastic), perform label encoding using Python's scikit-learn\n",
    "\n",
    "\n",
    "# Answer 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d12702-d3d7-42a3-b3f7-52875581bd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color    Size Material  Color_Encoded  Size_Encoded  Material_Encoded\n",
      "0    red   small     wood              2             2                 2\n",
      "1  green  medium    metal              1             1                 0\n",
      "2   blue   large  plastic              0             0                 1\n",
      "3  green  medium     wood              1             1                 2\n",
      "4    red   small    metal              2             2                 0\n",
      "5   blue   large  plastic              0             0                 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# create a sample dataset\n",
    "data = {'Color': ['red', 'green', 'blue', 'green', 'red', 'blue'],\n",
    "        'Size': ['small', 'medium', 'large', 'medium', 'small', 'large'],\n",
    "        'Material': ['wood', 'metal', 'plastic', 'wood', 'metal', 'plastic']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# create a label encoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# apply label encoding to each categorical variable\n",
    "df['Color_Encoded'] = le.fit_transform(df['Color'])\n",
    "df['Size_Encoded'] = le.fit_transform(df['Size'])\n",
    "df['Material_Encoded'] = le.fit_transform(df['Material'])\n",
    "\n",
    "# print the encoded dataset\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eafaab-d69d-45ed-8136-80f41b6a4c34",
   "metadata": {},
   "source": [
    "### Exlanation of the output \n",
    "As you can see, each categorical variable has been encoded into numerical values. The encoded values for each variable depend on the order in which they appear in the original dataset, and do not have any inherent meaning.\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc87ff7b-8e95-4819-bd7c-c2b1eff24c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a2cf059-b034-498a-a01b-52957a58226b",
   "metadata": {},
   "source": [
    "Q5. Calculate the covariance matrix for the following variables in a dataset: Age, Income, and Education\n",
    "level. Interpret the results.\n",
    "\n",
    "## Answer 5\n",
    "To calculate the covariance matrix for Age, Income, and Education level, we need a dataset that contains measurements for these three variables. Assuming we have such a dataset, we can calculate the covariance matrix using Python's NumPy library as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aec40993-fe12-424d-8cd8-ba1bcb134a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.8700e+02 1.4625e+05 3.0500e+01]\n",
      " [1.4625e+05 1.4578e+09 5.1950e+04]\n",
      " [3.0500e+01 5.1950e+04 7.3000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# python code to cslcute the covariances\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Data having the Attribute the age , Income, Education\n",
    "\n",
    "data = {'Age': [30, 18, 32, 40, 55],\n",
    "        'Income': [5000, 60000, 70000, 8000, 90000],\n",
    "        'Education': [13, 15, 16, 18, 20]}\n",
    "\n",
    "# creating the dataframe\n",
    "\n",
    "df =pd.DataFrame(data)\n",
    "\n",
    "# Covariances matrix\n",
    "\n",
    "cov_matrix = np.cov(df.T)\n",
    "\n",
    "print(cov_matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7ae6f1-eca2-46f8-8809-705b21026b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b0b463d-90eb-4dbe-b7e4-5cf4cf275db4",
   "metadata": {},
   "source": [
    "Q6. You are working on a machine learning project with a dataset containing several categorical\n",
    "variables, including \"Gender\" (Male/Female), \"Education Level\" (High School/Bachelor's/Master's/PhD),\n",
    "and \"Employment Status\" (Unemployed/Part-Time/Full-Time). Which encoding method would you use for\n",
    "each variable, and why?\n",
    "\n",
    "# Answer 6\n",
    "\n",
    "## 1 Gender(male/Female) :\n",
    "As you Gender has two male or Female so here we can give label to the data either 0 or 1 \n",
    "se We will use the **label Encoding.**\n",
    "\n",
    "####  In case of Gender we will use give prefrences to the label Encoding\n",
    "----------------\n",
    "\n",
    "## 2 Education level dataset(highScool/bachelor/master/phd--etc) :\n",
    "\n",
    " Since Education Level is an ordinal variable with a natural order to the categories (i.e., High School < Bachelor's < Master's < PhD), I would use ordinal encoding to encode it as 1, 2, 3, and 4, respectively.\n",
    "\n",
    "\n",
    "#### In Education we will use Ordinal Encoding\n",
    "---------\n",
    "\n",
    "## 3 Employment Status (Nominal categorical variable)\n",
    "\n",
    "Since Employment Status is a nominal variable with no natural order to the categories (i.e., Unemployed, Part-Time, and Full-Time are equally meaningful categories), I would use one-hot encoding to encode it. This would create three new binary variables: \"Unemployed\", \"Part-Time\", and \"Full-Time\", with a value of 1 indicating the corresponding category and 0 indicating the others.\n",
    "\n",
    "##### In Employment data I would use one-hot encoding to encode it.\n",
    "\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312dc779-75f4-4ec6-86cf-f58addc27de4",
   "metadata": {},
   "source": [
    "# Answer 7\n",
    "\n",
    "To calculate the covariance between each pair of variables, we need to have a dataset with measurements for \"Temperature\", \"Humidity\", \"Weather Condition\", and \"Wind Direction\". Assuming we have such a dataset, we can use Python's NumPy library to calculate the covariance matrix as follows:\n",
    "\n",
    "\n",
    "In this Temperature and Humidity are the Numerical data but Weather Condition and the Wind Direction Are the Categirical Dataset\n",
    "\n",
    "So we will First Convert the Categorical dataset into the Numerical Datset\n",
    "\n",
    "### python Code Given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57533431-e260-4d13-ab54-4ec2ec3b5645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 62.5  125.     1.25  -3.75]\n",
      " [125.   250.     2.5   -7.5 ]\n",
      " [  1.25   2.5    1.3    0.4 ]\n",
      " [ -3.75  -7.5    0.4    0.7 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import label encoder\n",
    "from sklearn import preprocessing\n",
    "  \n",
    "# label_encoder object knows how to understand word labels.\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# create a sample dataset\n",
    "data = {'Temperature': [20, 25, 30, 35, 40],\n",
    "        'Humidity': [30, 40, 50, 60, 70],\n",
    "        'Weather Condition': ['Sunny', 'Sunny', 'Cloudy', 'Rainy', 'Rainy'],\n",
    "        'Wind Direction': ['North', 'South', 'East', 'West', 'North']}\n",
    "\n",
    "\n",
    "# Categorical to Nuemrica;Dtaste\n",
    "\n",
    "df['Weather Condition']= label_encoder.fit_transform(df['Weather Condition'])\n",
    "df['Wind Direction']  = label_encoder.fit_transform(df['Wind Direction'])\n",
    "  \n",
    "\n",
    "# calculate the covariance matrix\n",
    "covariance_matrix = np.cov(df[['Temperature', 'Humidity' , 'Wind Direction' ,'Weather Condition']].T)\n",
    "\n",
    "# print the covariance matrix\n",
    "print(covariance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec7fe04-8046-4352-966a-a73000400f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3381c39-af0e-4c07-8b60-e01eb8bb43d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32aec07-3e1f-40ae-881a-ecc42f252458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c64c3a-427d-4f95-ba21-58859a8310ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86345751-4020-4f03-a15c-682c29206dce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0085854a-bd8e-457b-b4ea-5a4f0ee92ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9e0d77-8798-4218-87a7-d9c958af302c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3242a6d-5b26-4491-92fb-177ed69ab76b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12dbe6-81c5-434a-8846-5543295f62df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
